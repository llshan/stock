#!/usr/bin/env python3
"""
GCP Cloud Function å…¥å£ç‚¹
ç”¨äºå®šæœŸæ‰§è¡Œè‚¡ç¥¨åˆ†æå¹¶å°†ç»“æœå­˜å‚¨åˆ° Cloud Storage
"""

import os
import json
import logging
from logging_utils import setup_logging
from datetime import datetime
from typing import Dict, Any
from google.cloud import storage
from analyzer.comprehensive_analyzer import ComprehensiveStockAnalyzer
from analyzer.app.runner import run_analysis_for_symbols, build_operators
from data_service.downloaders.yfinance import YFinanceDataDownloader

# å°è¯•å¯¼å…¥æ•°æ®åº“åŠŸèƒ½
try:
    from cloud.database_setup import create_database_connection
    DATABASE_AVAILABLE = True
except ImportError:
    DATABASE_AVAILABLE = False
    logger.warning("æ•°æ®åº“åŠŸèƒ½ä¸å¯ç”¨ï¼Œå°†åªä½¿ç”¨Cloud Storageå­˜å‚¨")

# é…ç½®æ—¥å¿—ï¼ˆç»Ÿä¸€å…¥å£ï¼‰
setup_logging()
logger = logging.getLogger(__name__)

def stock_analysis_job(request=None):
    """
    Cloud Function ä¸»å‡½æ•°
    Args:
        request: HTTP è¯·æ±‚å¯¹è±¡ (ç”± Cloud Scheduler è§¦å‘æ—¶å¯èƒ½ä¸ºç©º)
    Returns:
        str: æ‰§è¡Œç»“æœæ¶ˆæ¯
    """
    try:
        logger.info("ğŸš€ å¼€å§‹æ‰§è¡Œå®šæ—¶è‚¡ç¥¨åˆ†æä»»åŠ¡")
        
        # ä»ç¯å¢ƒå˜é‡è·å–é…ç½®
        bucket_name = os.environ.get('GCS_BUCKET_NAME', 'stock-analysis-results')
        symbols_env = os.environ.get('STOCK_SYMBOLS', 'AAPL,GOOGL,MSFT,AMZN,META,TSLA,NVDA')
        symbols = [s.strip() for s in symbols_env.split(',')]
        
        logger.info(f"ğŸ“Š åˆ†æè‚¡ç¥¨: {', '.join(symbols)}")
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦å®Œæ•´æ•°æ®ä¸‹è½½
        download_full_data = os.environ.get('DOWNLOAD_FULL_DATA', 'false').lower() == 'true'
        
        if download_full_data:
            # æ‰§è¡Œå®Œæ•´æ•°æ®ä¸‹è½½å’Œå­˜å‚¨
            full_data_results = run_full_data_download(symbols)
        else:
            full_data_results = {'skipped': True, 'reason': 'DOWNLOAD_FULL_DATA not enabled'}
        
        # æ‰§è¡Œç»¼åˆåˆ†æ
        comprehensive_results = run_comprehensive_analysis(symbols)
        
        # æ‰§è¡Œä»·æ ¼ä¸‹è·Œç›‘æ§
        drop_monitor_results = run_price_drop_monitoring(symbols)
        
        # åˆå¹¶ç»“æœ
        combined_results = {
            'timestamp': datetime.now().isoformat(),
            'symbols_analyzed': symbols,
            'full_data_download': full_data_results,
            'comprehensive_analysis': comprehensive_results,
            'price_drop_monitoring': drop_monitor_results,
            'summary': generate_summary(comprehensive_results, drop_monitor_results)
        }
        
        # ä¸Šä¼ ç»“æœåˆ° Cloud Storage
        upload_results_to_gcs(combined_results, bucket_name)
        
        logger.info("âœ… è‚¡ç¥¨åˆ†æä»»åŠ¡å®Œæˆ")
        return json.dumps({
            'status': 'success',
            'message': f'åˆ†æäº† {len(symbols)} åªè‚¡ç¥¨',
            'timestamp': combined_results['timestamp']
        })
        
    except Exception as e:
        error_msg = f"âŒ åˆ†æä»»åŠ¡æ‰§è¡Œå¤±è´¥: {str(e)}"
        logger.error(error_msg)
        return json.dumps({
            'status': 'error',
            'message': error_msg,
            'timestamp': datetime.now().isoformat()
        })

def run_comprehensive_analysis(symbols: list) -> Dict[str, Any]:
    """æ‰§è¡Œç»¼åˆåˆ†æ"""
    try:
        logger.info("ğŸ“ˆ å¼€å§‹ç»¼åˆåˆ†æ...")
        results = run_analysis_for_symbols(symbols, db_path=os.environ.get('DB_PATH', 'stock_data.db'))
        processed_results = {}
        for symbol, data in results.items():
            ops = data.get('operators', {})
            processed_results[symbol] = {
                'operators': ops,
                'summary': data.get('summary', {})
            }
        logger.info("âœ… ç»¼åˆåˆ†æå®Œæˆ")
        return processed_results
        
    except Exception as e:
        logger.error(f"âŒ ç»¼åˆåˆ†æå¤±è´¥: {str(e)}")
        return {'error': str(e)}

def run_price_drop_monitoring(symbols: list) -> Dict[str, Any]:
    """æ‰§è¡Œä»·æ ¼ä¸‹è·Œç›‘æ§"""
    try:
        logger.info("âš ï¸ å¼€å§‹ä»·æ ¼ä¸‹è·Œç›‘æ§...")
        # 1å¤©ä¸7å¤©åˆ†åˆ«è¿è¡Œ
        res_1d = run_analysis_for_symbols(symbols, db_path=os.environ.get('DB_PATH', 'stock_data.db'), enabled_operators=['drop_alert'])
        res_7d = run_analysis_for_symbols(symbols, db_path=os.environ.get('DB_PATH', 'stock_data.db'), enabled_operators=['drop_alert_7d'])
        alerts_1d = []
        alerts_7d = []
        for sym, data in res_1d.items():
            da = data.get('operators', {}).get('drop_alert', {})
            if da and not da.get('error') and da.get('is_alert'):
                alerts_1d.append({'symbol': sym, **da})
        for sym, data in res_7d.items():
            da7 = data.get('operators', {}).get('drop_alert_7d', {})
            if da7 and not da7.get('error') and da7.get('is_alert'):
                alerts_7d.append({'symbol': sym, **da7})
        combined = {
            '1_day_monitoring': {'alerts': alerts_1d},
            '7_day_monitoring': {'alerts': alerts_7d},
            'urgent_alerts': [a for a in alerts_1d if abs(a.get('percent_change', 0)) >= 20]
        }
        logger.info("âœ… ä»·æ ¼ä¸‹è·Œç›‘æ§å®Œæˆ")
        return combined
        
    except Exception as e:
        logger.error(f"âŒ ä»·æ ¼ä¸‹è·Œç›‘æ§å¤±è´¥: {str(e)}")
        return {'error': str(e)}

def run_full_data_download(symbols: list) -> Dict[str, Any]:
    """æ‰§è¡Œå®Œæ•´è‚¡ç¥¨æ•°æ®ä¸‹è½½å’Œå­˜å‚¨"""
    try:
        logger.info("ğŸ’¾ å¼€å§‹å®Œæ•´æ•°æ®ä¸‹è½½å’Œå­˜å‚¨...")
        
        # åˆ›å»ºæ•°æ®ä¸‹è½½å™¨
        downloader = YFinanceDataDownloader()
        
        # åˆ›å»ºæ•°æ®åº“è¿æ¥ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        database = None
        if DATABASE_AVAILABLE:
            database = create_database_connection()
            if database:
                logger.info("âœ… æ•°æ®åº“è¿æ¥å·²å»ºç«‹")
        
        if not database:
            logger.warning("âš ï¸ æ•°æ®åº“ä¸å¯ç”¨ï¼Œè·³è¿‡æ•°æ®åº“å­˜å‚¨")
        
        # æ‰¹é‡ä¸‹è½½æ•°æ®
        results = downloader.batch_download(symbols, start_date="2020-01-01")
        
        # å­˜å‚¨åˆ°æ•°æ®åº“ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        storage_results = {}
        if database:
            for symbol, data in results.items():
                try:
                    if 'error' not in data:
                        database.store_comprehensive_data(symbol, data)
                        storage_results[symbol] = 'stored_successfully'
                    else:
                        storage_results[symbol] = f'download_failed: {data["error"]}'
                except Exception as e:
                    storage_results[symbol] = f'storage_failed: {str(e)}'
                    logger.error(f"å­˜å‚¨ {symbol} æ•°æ®å¤±è´¥: {str(e)}")
        
        # å…³é—­æ•°æ®åº“è¿æ¥
        if database:
            database.close()
        
        # ç”Ÿæˆæ‘˜è¦
        successful_downloads = len([r for r in results.values() if 'error' not in r])
        successful_storage = len([r for r in storage_results.values() if r == 'stored_successfully'])
        
        summary = {
            'total_symbols': len(symbols),
            'successful_downloads': successful_downloads,
            'failed_downloads': len(symbols) - successful_downloads,
            'successful_storage': successful_storage,
            'database_available': database is not None,
            'download_results': results,
            'storage_results': storage_results
        }
        
        logger.info(f"âœ… å®Œæ•´æ•°æ®ä¸‹è½½å®Œæˆ: {successful_downloads}/{len(symbols)} æˆåŠŸ")
        if database:
            logger.info(f"âœ… æ•°æ®åº“å­˜å‚¨å®Œæˆ: {successful_storage}/{len(symbols)} æˆåŠŸ")
        
        return summary
        
    except Exception as e:
        logger.error(f"âŒ å®Œæ•´æ•°æ®ä¸‹è½½å¤±è´¥: {str(e)}")
        return {'error': str(e)}

def extract_technical_summary(operators: Dict) -> Dict:
    """ä» operators ç»“æœæå–æŠ€æœ¯æ‘˜è¦"""
    rsi = operators.get('rsi', {})
    return {
        'trend': 'N/A',
        'rsi': rsi.get('rsi', 0),
        'rsi_signal': rsi.get('signal', 'N/A'),
    }

def extract_financial_summary(operators: Dict) -> Dict:
    """ä» operators ç»“æœæå–è´¢åŠ¡æ‘˜è¦"""
    ratios = operators.get('fin_ratios', {})
    health = operators.get('fin_health', {})
    return {
        'net_profit_margin': ratios.get('net_profit_margin', 0),
        'roe': ratios.get('roe', 0),
        'pe_ratio': ratios.get('pe_ratio', 0),
        'debt_ratio': ratios.get('debt_ratio', 0),
        'health_grade': health.get('grade', 'N/A'),
        'health_score': health.get('health_score', 0)
    }

def generate_summary(comprehensive_results: Dict, drop_monitor_results: Dict) -> Dict:
    """ç”Ÿæˆåˆ†ææ‘˜è¦"""
    summary = {
        'total_stocks_analyzed': 0,
        'successful_analysis': 0,
        'failed_analysis': 0,
        'high_rated_stocks': [],  # Açº§æˆ–Bçº§
        'drop_alerts_1d': 0,
        'drop_alerts_7d': 0,
        'urgent_drops': 0
    }
    
    # ç»Ÿè®¡ç»¼åˆåˆ†æç»“æœ
    if 'error' not in comprehensive_results:
        summary['total_stocks_analyzed'] = len(comprehensive_results)
        for symbol, data in comprehensive_results.items():
            if 'error' in data:
                summary['failed_analysis'] += 1
            else:
                summary['successful_analysis'] += 1
                # æ ¹æ®å¥åº·è¯„åˆ†åˆ¤æ–­é«˜è¯„çº§
                ops = data.get('operators', {})
                fin = extract_financial_summary(ops)
                if fin.get('health_grade', '').startswith(('A','B')):
                    summary['high_rated_stocks'].append({
                        'symbol': symbol,
                        'rating': fin.get('health_grade'),
                        'recommendation': ''
                    })
    
    # ç»Ÿè®¡ä»·æ ¼ä¸‹è·Œè­¦å‘Š
    if 'error' not in drop_monitor_results:
        summary['drop_alerts_1d'] = len(drop_monitor_results.get('1_day_monitoring', {}).get('alerts', []))
        summary['drop_alerts_7d'] = len(drop_monitor_results.get('7_day_monitoring', {}).get('alerts', []))
        summary['urgent_drops'] = len(drop_monitor_results.get('urgent_alerts', []))
    
    return summary

def upload_results_to_gcs(results: Dict, bucket_name: str):
    """ä¸Šä¼ ç»“æœåˆ° Google Cloud Storage"""
    try:
        # åˆå§‹åŒ– Storage å®¢æˆ·ç«¯
        client = storage.Client()
        bucket = client.bucket(bucket_name)
        
        # åˆ›å»ºæ–‡ä»¶åï¼ˆæŒ‰æ—¥æœŸæ—¶é—´ï¼‰
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f"stock_analysis_{timestamp}.json"
        
        # ä¸Šä¼ ä¸»ç»“æœæ–‡ä»¶
        blob = bucket.blob(f"results/{filename}")
        blob.upload_from_string(
            json.dumps(results, ensure_ascii=False, indent=2),
            content_type='application/json'
        )
        
        # ä¸Šä¼ æœ€æ–°ç»“æœï¼ˆè¦†ç›–ï¼‰
        latest_blob = bucket.blob("latest/stock_analysis_latest.json")
        latest_blob.upload_from_string(
            json.dumps(results, ensure_ascii=False, indent=2),
            content_type='application/json'
        )
        
        logger.info(f"ğŸ“¤ ç»“æœå·²ä¸Šä¼ åˆ° GCS: gs://{bucket_name}/{filename}")
        
        # å¦‚æœæœ‰ç´§æ€¥è­¦å‘Šï¼Œåˆ›å»ºå•ç‹¬çš„è­¦å‘Šæ–‡ä»¶
        urgent_alerts = results.get('price_drop_monitoring', {}).get('urgent_alerts', [])
        if urgent_alerts:
            alert_filename = f"alerts/urgent_alerts_{timestamp}.json"
            alert_blob = bucket.blob(alert_filename)
            alert_blob.upload_from_string(
                json.dumps({
                    'timestamp': results['timestamp'],
                    'urgent_alerts': urgent_alerts
                }, ensure_ascii=False, indent=2),
                content_type='application/json'
            )
            logger.info(f"ğŸš¨ ç´§æ€¥è­¦å‘Šå·²ä¸Šä¼ : gs://{bucket_name}/{alert_filename}")
        
    except Exception as e:
        logger.error(f"âŒ ä¸Šä¼ åˆ° GCS å¤±è´¥: {str(e)}")
        raise

# æœ¬åœ°æµ‹è¯•å…¥å£ç‚¹
if __name__ == "__main__":
    logger.info("ğŸ§ª æœ¬åœ°æµ‹è¯•æ¨¡å¼")
    os.environ.setdefault('GCS_BUCKET_NAME', 'test-stock-analysis')
    os.environ.setdefault('STOCK_SYMBOLS', 'AAPL,GOOGL,MSFT')
    
    result = stock_analysis_job()
    logger.info("ğŸ“Š æµ‹è¯•ç»“æœ:")
    logger.info(result)
